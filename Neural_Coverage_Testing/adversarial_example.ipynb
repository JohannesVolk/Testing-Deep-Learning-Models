{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import network.network as Network\n",
    "import network.mnist_loader as mnist_loader\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import cupy as cp\n",
    "import numpy as np\n",
    "import time as time\n",
    "\n",
    "import network.capture as capture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, validation_data, test_data = mnist_loader.load_data_wrapper()\n",
    "\n",
    "training_data = list(training_data)\n",
    "validation_data = list(validation_data)\n",
    "test_data = list(test_data)\n",
    "\n",
    "#bigNetwork: 784x392x196x196x10 neurons\n",
    "#smallNetwork: 784x100x10 neurnsta)\n",
    "\n",
    "with open('network/bigNetwork.pkl', 'rb') as f:\n",
    "    u = pickle._Unpickler(f)\n",
    "    u.encoding = 'latin1'\n",
    "    net = u.load()\n",
    "\n",
    "net.biases = list(map(cp.array,net.biases))\n",
    "net.weights = list(map(cp.array,net.weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_new_network():\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    newNet = Network.Network([392, 392, 1966, 98, 10])\n",
    "    newNet.SGD(training_data, 30, 100, 10, test_data=test_data)\n",
    "\n",
    "    end = time.time()\n",
    "    print(end - start) \n",
    "\n",
    "    \n",
    "    with open('network/newNet.pkl', 'rb') as file:\n",
    "        pickle.dump(newNet, file)\n",
    "    return newNet\n",
    "\n",
    "def evaluateNet(net):\n",
    "    print(\"start eval\")\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    print(net.evaluate(test_data))\n",
    "\n",
    "    print(\"took \" + str(round(time.time() - start,2)) + \"seconds\")\n",
    "evaluateNet(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('network/pattern.pkl', 'rb') as pattern_file:\n",
    "  u_pattern = pickle._Unpickler(pattern_file)\n",
    "  u_pattern.encoding = 'latin1'\n",
    "  pattern= u_pattern.load()\n",
    "\n",
    "#generate new patterns (inefficient implementation and might take a long time)\n",
    "#    \n",
    "#pattern = net.extract_src_pattern(test\n",
    "#with open('network/newPattern.pkl', 'wb') as file2:  \n",
    "#       pickle.dump(pattern, file2)_data)\n",
    "\n",
    "def print_pattern(pattern):\n",
    "    # print(pattern)\n",
    "\n",
    "    l = []\n",
    "    for min, max in pattern:\n",
    "        # this is the function that aggregates the tuple of src activations\n",
    "        # might change this to better display the intervallsin pattern:\n",
    "        l.append(max+min);\n",
    "    l = list(map(cp.asnumpy,l))\n",
    "    l = np.stack(l)\n",
    "    l = l.res\n",
    "    plt.imshow(l)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print all patterns\n",
    "#\n",
    "#for i in range(0,10#):\n",
    "   #print_pattern(pattern[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start live-classification\n",
    "# need to specifiy the video source within the function\n",
    "# exit by pressing q in the opened window\n",
    "\n",
    "capture.capturenow(net,pattern)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are some functions provided by the source project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"The sigmoid function.\"\"\"\n",
    "    return 1.0/(1.0+cp.exp(-z))\n",
    "                                                                                                                                                                                \n",
    "def sigmoid_prime(z):\n",
    "    \"\"\"Derivative of the sigmoid function.\"\"\"\n",
    "    return sigmoid(z)*(1-sigmoid(z))\n",
    "\n",
    "def input_derivative(net, x, y):\n",
    "    \"\"\" Calculate derivatives wrt the inputs\"\"\"\n",
    "    nabla_b = [cp.zeros(b.shape) for b in net.biases]\n",
    "    nabla_w = [cp.zeros(w.shape) for w in net.weights]\n",
    "    \n",
    "    # feedforward\n",
    "    activation = x\n",
    "    activations = [x] # list to store all the activations, layer by layer\n",
    "    zs = [] # list to store all the z vectors, layer by layer\n",
    "    for b, w in zip(net.biases, net.weights):\n",
    "        z = cp.dot(w, activation)+b\n",
    "        zs.append(z)\n",
    "        activation = sigmoid(z)\n",
    "        activations.append(activation)\n",
    "        \n",
    "    # backward pass\n",
    "    delta = net.cost_derivative(activations[-1], y) * \\\n",
    "        sigmoid_prime(zs[-1])\n",
    "    nabla_b[-1] = delta\n",
    "    nabla_w[-1] = cp.dot(delta, activations[-2].transpose())\n",
    "\n",
    "    for l in range(2, net.num_layers):\n",
    "        z = zs[-l]\n",
    "        sp = sigmoid_prime(z)\n",
    "        delta = cp.dot(net.weights[-l+1].transpose(), delta) * sp\n",
    "        nabla_b[-l] = delta\n",
    "        nabla_w[-l] = cp.dot(delta, activations[-l-1].transpose())\n",
    "        \n",
    "    # Return derivatives WRT to input\n",
    "    return net.weights[0].T.dot(delta)\n",
    "\n",
    "def adversarial(net, n, steps, eta):\n",
    "    \"\"\"\n",
    "    net : network object\n",
    "        neural network instance to use\n",
    "    n : integer\n",
    "        our goal label (just an int, the function transforms it into a one-hot vector)\n",
    "    steps : integer\n",
    "        number of steps for gradient descent\n",
    "    eta : float\n",
    "        step size for gradient descent\n",
    "    \"\"\"\n",
    "    # Set the goal output\n",
    "    goal = cp.zeros((10, 1))\n",
    "    goal[n] = 1\n",
    "\n",
    "    # Create a random image to initialize gradient descent with\n",
    "    x = cp.random.normal(.5, .3, (784, 1))\n",
    "\n",
    "    # Gradient descent on the input\n",
    "    for i in range(steps):\n",
    "        # Calculate the derivative\n",
    "        d = input_derivative(net,x,goal)\n",
    "        \n",
    "        # The GD update on x\n",
    "        x -= eta * d\n",
    "        \n",
    "    return x\n",
    "\n",
    "# Wrapper function\n",
    "def generate(n):\n",
    "   \n",
    "    a = adversarial(net, n, 10000, 3)\n",
    "    x = cp.round(net.feedforward(a), 2)\n",
    "    print(str(np.round(x, 2)).replace(\"\\n\",\"\"))\n",
    "    print('Network prediction: ' + str(cp.argmax(x)) + '\\n')\n",
    "    net.evaluate_src_pattern(pattern,a)\n",
    "\n",
    "    \n",
    "    print('Adversarial Example: ')\n",
    "    plt.imshow(np.reshape(cp.asnumpy(a),(28,28)), cmap='viridis')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a attack pattern for specified label\n",
    "# can yield poor results with big network due to small learning rate / iteration count \n",
    "generate(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sneaky_adversarial(net, n, x_target, steps, eta, lam=.05):\n",
    "    \"\"\"\n",
    "    net : network object\n",
    "        neural network instance to use\n",
    "    n : integer\n",
    "        our goal label (just an int, the function transforms it into a one-hot vector)\n",
    "    x_target : numpy vector\n",
    "        our goal image for the adversarial example\n",
    "    steps : integer\n",
    "        number of steps for gradient descent\n",
    "    eta : float\n",
    "        step size for gradient descent\n",
    "    lam : float\n",
    "        lambda, our regularization parameter. Default is .05\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set the goal output\n",
    "    goal = cp.zeros((10, 1))\n",
    "    goal[n] = 1\n",
    "\n",
    "    # Create a random image to initialize gradient descent with\n",
    "    x = cp.random.normal(.5, .3, (784, 1))\n",
    "\n",
    "    # Gradient descent on the input\n",
    "    for i in cp.arange(steps):\n",
    "        # Calculate the derivative\n",
    "        d = input_derivative(net,x,goal)\n",
    "        \n",
    "        # The GD update on x, with an added penalty to the cost function\n",
    "        # ONLY CHANGE IS RIGHT HERE!!!\n",
    "\n",
    "        x -= eta * (d+lam * (x-x_target))\n",
    "\n",
    "    return x\n",
    "\n",
    "# Wrapper function\n",
    "def sneaky_generate(n, m):\n",
    "    \"\"\"\n",
    "    n: int 0-9, the target number to match\n",
    "    m: index of example image to use (from the test set)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Find random instance of m in test set\n",
    "    idx = np.random.randint(0,9999)\n",
    "\n",
    "    while test_data[idx][1] != m:\n",
    "        idx += 1\n",
    "    \n",
    "    a = sneaky_adversarial(net, n, test_data[idx][0], 10000, 3)\n",
    "    x = cp.round(net.feedforward(a), 2)\n",
    "    \n",
    "    print('\\nWhat we want our adversarial example to look like: ')\n",
    "    plt.imshow(np.reshape(cp.asnumpy(test_data[idx][0]),(28,28)), cmap='viridis')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    print('\\n')\n",
    "    \n",
    "    print('Adversarial Example: ')\n",
    "    \n",
    "    plt.imshow(np.reshape(cp.asnumpy(a),(28,28)), cmap='viridis')\n",
    "    plt.show()\n",
    "    print(str(np.round(x, 2)).replace(\"\\n\",\"\"))\n",
    "    print('Network prediction: ' + str(cp.argmax(a)) + '\\n')\n",
    "    net.evaluate_src_pattern(pattern,a)\n",
    "\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sneaky_generate(target label, target digit)\n",
    "# generate adversarial examples\n",
    "# some pairs work better than other\n",
    "adv_ex = sneaky_generate(3,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(n, data, steps):\n",
    "    \"\"\"\n",
    "    n : integer\n",
    "        number of adversarial examples to generate\n",
    "    data : list of tuples\n",
    "        data set to generate adversarial examples using\n",
    "    \"\"\"\n",
    "    # Our augmented training set:\n",
    "    augmented = []\n",
    "    \n",
    "    for i in cp.arange(n):\n",
    "        # Progress \"bar\"\n",
    "        if i % 100 == 0:\n",
    "            print(\"Generated digits: \" + str(i))\n",
    "            \n",
    "        # Randomly choose a digit that the example will look like\n",
    "        rnd_actual_digit = np.random.randint(10)\n",
    "        \n",
    "        # Find random instance of rnd_actual_digit in the training set\n",
    "        rnd_actual_idx = np.random.randint(len(data))\n",
    "        while cp.argmax(data[rnd_actual_idx][1]) != rnd_actual_digit:\n",
    "            rnd_actual_idx = np.random.randint(len(data))\n",
    "        x_target = data[rnd_actual_idx][0]\n",
    "        \n",
    "        # Choose value for adversarial attack\n",
    "        rnd_fake_digit = cp.random.randint(10)\n",
    "        \n",
    "        # Generate adversarial example\n",
    "        x_adversarial = sneaky_adversarial(net, rnd_fake_digit, x_target, steps, 1)\n",
    "        \n",
    "        # Add new data\n",
    "        y_actual = data[rnd_actual_idx][1]\n",
    "        \n",
    "        augmented.append((x_adversarial, y_actual))\n",
    "        \n",
    "    return augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate augmented data set\n",
    "# This will take quite a while ~(20 min per 10000)\n",
    "augmented = augment_data(10000, training_data, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_augmented(i, augmented):\n",
    "    # Show image\n",
    "    print('Image: \\n')\n",
    "    plt.imshow(np.reshape(cp.asnumpy(augmented[i][0]),(28,28)), cmap='viridis')\n",
    "    plt.show()\n",
    "    \n",
    "    # Show original network prediction\n",
    "    print('Original network prediction: \\n')\n",
    "    print(cp.round(net.feedforward(augmented[i][0]), 2))\n",
    "    \n",
    "    # Show label\n",
    "    print('\\nLabel: \\n')\n",
    "    print(augmented[i][1])\n",
    "\n",
    "# check i^th adversarial image\n",
    "check_augmented(853, augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new network\n",
    "net2 = Network.Network([784,392,196,196,10])\n",
    "\n",
    "# Train on augmented + original training set\n",
    "net2.SGD(augmented + training_data, 30, 100, 10, test_data=test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's checkout the accuracy of our newly trained network on adversarial examples from the new adversarial test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"first network:\")\n",
    "evaluateNet(net)\n",
    "\n",
    "print(\"\\nsecond network:\")\n",
    "evaluateNet(net2)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "226b0bfe565b1b26ba0fac29fd4d427cb0aeca81c7a6f675349b9931f46b38c7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
